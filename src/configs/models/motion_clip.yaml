seed: 42

model:
  target: src.models.motion_clip.MotionCLIP
  model_kwargs:
    output_size: 768
    n_heads: 8
    n_encoder_layers: 8
    init_latent_scale: 1
    text_feature_name: openai/clip-vit-large-patch14
    motion_representation: intergen_262
    dropout: 0.25
    n_labels: 40
    cls_weight: 0.1
    action_mask_coef: 31

  training_kwargs:
    optimizer:
      target: torch.optim.Adam
      lr: 1e-4
    scheduler: constant_schedule_with_warmup
    warmup_steps: 1000


trainer:
  max_epochs: 40


dataloader:
  batch_size: 128
  val_batch_size: 32
  num_workers: 32
  pin_memory: True
  persistent_workers: True
